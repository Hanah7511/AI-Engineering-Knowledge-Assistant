#===================AI Engineering Knowledge Assistant=================

Production-Grade Hybrid RAG System (CLI-Based)

A recruiter-ready, production-level Retrieval-Augmented Generation (RAG) system built using LangChain, ChromaDB, and OpenAI to answer technical questions from your own documentation and project files.

 Project Overview

The AI Engineering Knowledge Assistant is a hybrid RAG pipeline that retrieves relevant documents from a local vector database and generates grounded answers using an LLM.

Unlike basic chatbots, this system:

-Uses your real project files as knowledge

-Prevents hallucination with strict context grounding

-Tracks cost, performance, and confidence

-Implements production features like retry logic, caching, and fallback

This simulates how real companies build internal AI assistants for:

-Engineering documentation

-MLOps pipelines

-Technical knowledge bases

-Developer copilots

###Key Features (Recruiter-Ready)
####Advanced Retrieval System

-Similarity Search (Fast semantic retrieval)

-MMR Retrieval (Diverse document selection)

-Dynamic Retriever Switching

-Source File Filtering (Enterprise-style)

###Production AI Capabilities

-Hybrid RAG Architecture (Local + LLM)

-Modern LCEL Chain (LangChain 2024+)

-Retry Logic with Exponential Backoff

-Safe Fallback (Zero extra LLM cost)

-Query Caching System

-Confidence Scoring

-Cost Tracking per Query

###Observability & Analytics

-Response time tracking

-Token usage tracking

-API cost monitoring

-ROI analytics

-Export to CSV / JSON

####System Architecture
User Query (CLI)
       â†“
EnhancedProductionRAG (Core Engine)
       â†“
Dynamic Retrieval Layer
   â”œâ”€â”€ Similarity Retriever
   â””â”€â”€ MMR Retriever
       â†“
Chroma Vector Database (Local)
       â†“
LCEL Runnable Chain (LangChain)
       â†“
OpenAI GPT-4o-mini (Generation)
       â†“
Answer + Sources + Metrics + Cost Tracking

####Tech Stack
#Category	          Technology
LLM	OpenAI            GPT-4o-mini
Framework	          LangChain (LCEL Architecture)
Vector Database	      ChromaDB (Local)
Embeddings	          HuggingFace Sentence Transformers
Backend	              Python 3.10+
Interface	          CLI (Production Stable)
Analytics	          Custom Metrics + ROI Tracking

ğŸ“‚ Project Structure
AI-Engineering-Knowlege-Assistance/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/          # Knowledge base files
â”‚   â”œâ”€â”€ vector_store/       # Chroma DB (auto generated)
â”‚   â””â”€â”€ query_cache.pkl     # Cache system
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â””â”€â”€ knowledge_base.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â””â”€â”€ rag_pipeline.py     # Core RAG Engine
â”‚   â”‚
â”‚   â””â”€â”€ interface/
â”‚       â””â”€â”€ main.py             # CLI Interface
â”‚
â”œâ”€â”€ exports/                    # Exported analytics
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md

âš™ï¸ How to Run the Project (CLI)

1ï¸. Install Dependencies
pip install -r requirements.txt

2ï¸. Set Environment Variable
Create a .env file in project root:

OPENAI_API_KEY=your_api_key_here

3ï¸. Run the CLI System
python src/interface/main.py


You should see:

âœ… System Initialized Successfully!
ğŸš€ Ready to answer your engineering questions!

ğŸ’¬ Example Usage

Ask questions like:

-What is RAG architecture?
-Explain the knowledge base class
-How does the ML pipeline work?


The system will return:

-Grounded AI Answer

-Source Documents

-Confidence Score

-Cost Metrics

-Performance Analytics

####Production Engineering Highlights (Why This Project is Strong)

-Production-grade RAG architecture

-Modern LangChain LCEL implementation

-Multi-retriever system (Similarity + MMR)

-Enterprise source filtering

-Retry + Fallback reliability system

-Query caching for performance optimization

-Business ROI analytics tracking

-Exportable metrics (CSV & JSON)

-Laptop-safe optimization (8GB RAM friendly)

##Ideal Use Cases

-AI Engineering Portfolio Project

-Final Year Major Project (CSE AI/ML)

-Internal Documentation Assistant

-MLOps Knowledge Assistant

-Developer Copilot (Private Docs)

####Notes

-Fully functional via CLI (stable)

-Streamlit UI is optional (can be added later)

-Uses local embeddings to reduce API cost

-Designed for recruiter and internship evaluation

#Author
HANA AL HARIS
AI/ML Engineering Portfolio Project
Final Year BTech (CSE - AI/ML)

#License

For educational and portfolio use.